# Copyright 2025 Moonlight Technologies Inc.. All Rights Reserved.
# Auth Masahiro Aoki

# 機能説明書: 分散脳シミュレーション

Last Updated: 2025-11-26

## 1. 概要

分散脳シミュレーションは、人間の脳の機能的専門化と全体的な協調動作に着想を得た、大規模なスパイキングニューラルネットワーク（SNN）アーキテクチャです。このシミュレーションは、複数の独立したプロセス（ノード）を協調させて動作させることにより、複雑なマルチモーダルタスクの処理を実現します。

中心的な役割を果たす**PFC (Prefrontal Cortex) 決定エンジン**が司令塔となり、視覚、聴覚、言語、運動などの専門機能を持つモジュールに対して、入力された情報に基づいてタスクを動的にルーティングします。本システムは、研究開発者が脳の情報処理メカニズムを探求し、より高度なAIシステムを構築するための柔軟でスケーラブルなプラットフォームを提供します。

## 2. アーキテクチャ

本シミュレーションは、`torch.distributed`ライブラリを基盤としたマスター/スレーブ型の分散アーキテクチャを採用しています。

- **マスターノード (Rank 0):**
  - **PFC (Prefrontal Cortex) 決定エンジン**が割り当てられます。
  - すべてのタスクの受け入れ、解釈、およびスレーブノードへの割り当てを担当します。
  - システム全体の認知負荷を計算し、自身の動作を調整します。

- **スレーブノード (Rank > 0):**
  - 視覚、言語、運動といった特定の機能を担当するモジュールが割り当てられます。
  - PFCからの指示を待ち、割り当てられたタスクを実行して結果を返します。

- **プロセス間通信:**
  - ノード間のデータ通信は、`torch.distributed`の`send`および`recv`プリミティブを使用して行われます。
  - 本システムは、複数のデータ（例: テキストと画像）を一度に送信するための、堅牢な**マニフェストベースの通信プロトコル**を実装しています。PFCはまず、後続のデータの内容（例: `[テキストあり, 画像あり, 音声なし]`）を示すマニフェストテンソルを送信し、その後、実際のデータテンソルを順番に送信します。これにより、各専門ノードが`MultiModalEvoSpikeNetLM`のようなマルチモーダルモデルを扱うことが可能になります。

- **階層的モジュール構造:**
  - 特定の機能（特に言語、視覚、聴覚）は、さらに詳細なサブタスクを実行する子ノードを持つ階層構造を形成することができます。例えば、「言語」モジュールは、「単語埋め込み」「TASエンコーディング」といった子プロセスを管理し、より複雑な言語処理パイプラインを構築します。

![Architecture Diagram](https://dummyimage.com/800x400/cccccc/000000.png&text=Architecture+Diagram)
*(図: PFCを中心としたマスター/スレーブ構成とノード間通信の概念図)*

## 3. 主要コンポーネント

### 3.1. PFCDecisionEngine

`evospikenet/pfc.py` に実装されているPFC決定エンジンは、シミュレーション全体の中核です。

- **役割:**
  - **タスクルーティング:** 入力データ（テキスト、画像、音声）の内容を解釈し、最適な機能モジュールへタスクを割り当てます。
  - **ワーキングメモリ:** `LIFNeuronLayer`を用いて短期的な情報を保持し、連続したタスク処理の文脈を維持します。
  - **認知負荷の計算:** 意思決定の不確実性をエントロピーとして計算し、システム全体の「認知負荷」を定量化します。

- **ユニークな機能:**
  - **ChronoSpikeAttention:** 時間的なスパイク情報を処理するために設計された独自のアテンション機構。入力されたスパイク列のどの部分に注目すべきかを判断し、意思決定の精度を高めます。
  - **量子インスパイアード・フィードバックループ:**
    - 認知負荷（エントロピー）の値を用いて、`QuantumFeedbackSimulator`が2量子ビットの回路をシミュレートします。
    - このシミュレーションから得られる期待値をフィードバック信号として、PFCのワーキングメモリ（LIF層）の膜電位を動的に変調します。
    - これにより、PFCは自身の意思決定の複雑さに応じて、内部状態を自己調整するという高度なメタ認知機能を実現しています。

### 3.2. 各種機能モジュール

PFCの配下で動作する、特定のタスクに特化したスレーブモジュールです。

- **VisualModule:** 画像データを処理します。階層化されている場合、エッジ検出、形状抽出、物体分類などのサブモジュールを持ちます。
- **AuditoryModule:** 音声データを処理します。MFCC特徴抽出や音素分類などのサブモジュールに分割できます。
- **LanguageModule:** テキストデータを処理します。単語埋め込み、エンコーディング、RAG（Retrieval-Augmented Generation）などの複雑なパイプラインを子プロセスとして持ちます。
- **MotorModule:** 運動制御信号を生成します。
- **SpeechGenerationModule:** テキストから音声を合成します。

## 4. 実行と操作方法

シミュレーションの管理は、`frontend/pages/distributed_brain.py`で実装されたWeb UIから行います。

### 4.1. UI概要

UIは主に「Node Configuration」「Brain Simulation」「Learning」の3つのタブで構成されています。

- **Simulation Control (常時表示):**
  - **Select Simulation Type:** 実行するシミュレーションの構成を選択します（後述）。
  - **Start/Stop Nodes:** シミュレーション全体の起動と停止を制御します。

### 4.2. 操作フロー

1.  **シミュレーションタイプの選択:**
    - 「Simulation Control」パネルのドロップダウンから、「Language Focus」などの事前定義された構成を選択します。

2.  **ノード構成 (Node Configurationタブ):**
    - 選択したタイプに基づいて、必要なノード（PFC、Visualなど）の一覧が表示されます。
    - 各ノード（Rank > 0）をどのホストで実行するかをドロップダウンで割り当てます。`localhost`を選択すれば、すべてのプロセスがローカルで実行されます。リモートホストを追加・設定することも可能です。

3.  **シミュレーションの開始:**
    - 「Start Nodes」ボタンをクリックすると、設定に従って各ノードのプロセスが起動します。ローカルノードは`subprocess`で、リモートノードはSSH経由でバックグラウンド実行されます。

4.  **クエリの実行 (Brain Simulationタブ):**
    - シミュレーションが実行状態になると、このタブからインタラクションが可能になります。
    - テキストプロンプトの入力、画像・音声ファイルのアップロードが可能です。
    - 「Execute Query」ボタンを押すと、入力されたデータがAPI経由でPFC (Rank 0) に送信されます。

### 4.3. 可視化とモニタリング

「Brain Simulation」タブでは、シミュレーションの内部状態がリアルタイムで可視化されます。

- **Live Simulation Graph:**
  - Cytoscapeを利用したネットワークグラフです。
  - 各ノードの状態（色で表現）と、ノード間のアクティブな通信（ハイライトされたエッジ）が表示されます。
- **PFC Energy and Entropy:**
  - PFCのエネルギー消費と認知負荷（エントロピー）の推移を時系列で表示します。
- **PFC Spike Train / Membrane Potential:**
  - PFCのワーキングメモリを構成するニューロン群の発火パターンと膜電位の分布を可視化し、内部状態を詳細に分析できます。
- **Node Logs:**
  - ドロップダウンでノードを選択すると、そのノードの標準出力ログ（`/tmp/sim_rank_{rank}.log`）が表示されます。分散システムのデバッグに不可欠です。

## 5. データフロー

ユーザーがクエリを実行した際の、典型的なデータの流れは以下の通りです。

1.  **UI → API:** ユーザーがUIからプロンプト（テキスト/画像/音声）を送信します。データはBase64エンコードされ、APIサーバーの`/api/distributed_brain/prompt`エンドポイントにPOSTされます。
2.  **API → PFC:** APIサーバーは受け取ったデータを解釈し、シミュレーションプロセス（特にPFC）がポーリングするためのファイル（`/tmp/evospikenet_prompt_{uuid}.json`）として保存します。
3.  **PFC (タスク解釈とルーティング):**
    - PFC (Rank 0) はプロンプトファイルを検知して読み込みます。
    - データの内容（画像があるか、音声があるか）を判断し、処理を依頼する最適なスレーブノード（例: `VisualModule` at Rank 1）を決定します。
4.  **PFC → スレーブ (データ送信):**
    - PFCは、設計された通信プロトコルに従い、まずマニフェストテンソルをターゲットランクに送信します。
    - 続いて、プロンプトに含まれる関連データ（例: テキストテンソルと画像テンソル）を順番に送信します。
5.  **スレーブ (タスク実行):**
    - スレーブノードは、まずマニフェストを受信し、後続で送られてくるデータの種類と数を把握します。
    - 必要な回数だけデータテンソルを受信し、それらを自身のモデル（`MultiModalEvoSpikeNetLM`など）に渡してタスクを実行し、結果のテンソルを生成します。
6.  **スレーブ → PFC (結果返信):**
    - スレーブノードは、処理結果のテンソルをPFC (Rank 0) に`dist.send`で返信します。
7.  **PFC → API:**
    - PFCは最終結果を受け取り、人間が解読可能な形式（テキストなど）に変換した後、APIサーバーの`/api/distributed_brain/result`エンドポイントにPOSTします。
8.  **API → UI:**
    - UIは定期的にAPIサーバーに問い合わせを行い、最新の結果を「Query Response」エリアに表示します。

## 6. 設定可能なシミュレーション構成

`simulation-type-dropdown`から、以下の事前定義済み構成を選択できます。

- **Language Focus (9-Proc):**
  - 言語処理に特化した構成。PFC、主要モジュールに加え、言語処理パイプライン（Embed, TAS）のための専用ノードが含まれます。
- **Image Focus (11-Proc):**
  - 視覚処理に特化した構成。`VisualModule`が親ノードとなり、エッジ検出(Edge)、形状抽出(Shape)、物体分類(Object)の子ノードを持つ階層構造を形成します。
- **Audio Focus (12-Proc):**
  - 聴覚情報処理に特化した構成。`AuditoryModule`と`SpeechGenerationModule`がそれぞれ子ノードを持ち、音声認識と音声合成のパイプラインを形成します。
- **Motor Focus (11-Proc):**
    - 運動制御に特化した構成。`MotorModule`が親ノードとなり、軌道生成(Traj)、PID制御(Cereb)、PWM信号生成(PWM)の子ノードを持ちます。
- **Full Brain (21-Proc):**
  - 上記のすべての階層化モジュールを統合した、最大規模のシミュレーション構成です。
