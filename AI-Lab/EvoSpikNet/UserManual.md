# Copyright 2025 Moonlight Technologies Inc.. All Rights Reserved.
# Auth Masahiro Aoki

# EvoSpikeNet Dashboard ユーザーマニュアル

## 1. はじめに

このドキュメントは、`EvoSpikeNet Dashboard`の各機能の使用方法と、その背後にある技術的な実装について解説します。このダッシュボードは、EvoSpikeNetフレームワークの様々な機能をブラウザからインタラクティブに実行し、可視化するためのツールです。

## 2. セットアップとインストール

このプロジェクトを実行するには、Python 3.8以上の環境が必要です。

### 2.1. 依存関係のインストール

プロジェクトのルートディレクトリで以下のコマンドを実行し、必要なライブラリをすべてインストールします。

```bash
pip install -e .
```

このコマンドは、`pyproject.toml`ファイルに記載されている以下の主要な依存関係を自動的にインストールします。
- `torch`
- `pandas`
- `plotly`
- `dash`
- `networkx`
- `tqdm`
- `wikipedia-api`
- `beautifulsoup4`
- `psutil`
- `snntorch`
- `transformers`
- `openai`

`-e`フラグは「編集可能モード」でインストールすることを意味し、ソースコードの変更が即座に反映されるため、開発に推奨されます。

### 2.2. （任意）OpenAI APIキーの設定

`examples/generate_distilled_dataset.py`スクリプト（LLMによるデータ蒸留機能）を使用するには、OpenAIのAPIキーが必要です。以下の環境変数を設定してください。

```bash
export OPENAI_API_KEY="your_api_key_here"
```

## 3. 主要インターフェース

ダッシュボードは、主に3つのタブで構成されています。

1.  **Simulations & Models (シミュレーション & モデル) タブ:**
    -   基本的なSNNシミュレーションや、訓練済みモデルの推論を実行するための機能が集約されています。
    -   `Select Model / Feature`ドロップダウンで機能を選択し、表示されるパラメータを設定して「Run Execution」ボタンで実行します。
2.  **LM Training (Advanced) (LM訓練 - 高度) タブ:**
    -   Wikipediaや青空文庫などの外部データソースを用いて、言語モデル(`EvoSpikeNetLM`)を柔軟に訓練するための専用インターフェースです。詳細は`4.5`で解説します。
3.  **System & Data (システム & データ) タブ:**
    -   テストの実行、データの生成、簡易的なモデル訓練など、プロジェクトの管理タスクを実行するための「コマンドパネル」が配置されています。

---

## 4. 機能別 詳細解説

### 4.1. Standard SNN Simulation (標準SNNシミュレーション)

-   **目的:**
    基本的なLIF（Leaky Integrate-and-Fire）ニューロンとスパースなシナプス接続で構成される、コアなSNNモデルの動作をシミュレートします。
-   **パラメータ:**
    -   `Input Neurons`: 入力層のニューロン数。
    -   `Output Neurons`: 出力層のニューロン数。
    -   `Time Steps`: シミュレーションを実行する時間ステップ数。
    -   `Connectivity Ratio`: 入力層と出力層のニューロンがランダムに接続される割合（0.0〜1.0）。
-   **出力:**
    出力層ニューロンの発火活動を示すラスタプロットが表示されます。黒い点が各タイムステップでのニューロンの発火（スパイク）を表します。
-   **論理的実装:**
    `Run Execution`ボタンを押すと、`frontend/app.py`内の`run_standard_snn_simulation`関数が呼び出されます。この関数は、`evospikenet.core`の`LIFNeuronLayer`, `SynapseMatrixCSR`, `SNNModel`クラスを使い、指定されたパラメータでSNNを構築します。`DataMonitorHook`でスパイクを記録し、`InsightEngine`でラスタプロットを生成しています。

### 4.2. Entangled Synchrony Layer (量子インスパイアード同期レイヤー)

-   **目的:**
    量子もつれに着想を得た特殊なレイヤーの動作を検証します。入力されたスパイクとコンテキスト情報に基づき、ニューロン群の同期的な発火を確率的に生成します。
-   **パラメータ:**
    -   `Number of Neurons`: レイヤー内のニューロン数。
    -   `Initial Strength (0-255)`: 同期強度の初期値。値が大きいほど、ニューロン群が同期して発火しやすくなります。
-   **出力:**
    生成された同期スパイクのパターンがヒートマップとして表示されます。
-   **論理的実装:**
    `run_synchrony_layer_simulation`関数が呼び出されます。この関数は`evospikenet.core`の`EntangledSynchronyLayer`をインスタンス化し、ランダムなスパイクとコンテキストデータを生成してフォワードパスを実行します。出力は1タイムステップのスパイクパターンとして可視化されます。

### 4.3. Hardware Fitness Evaluator (ハードウェア適応度評価)

-   **目的:**
    シミュレーションの性能だけでなく、消費電力や温度などのハードウェア指標を考慮した「適応度」を計算する評価関数の動作をデモします。
-   **パラメータ:**
    -   `Power (e.g., 100-150)`: シミュレートされた消費電力。
    -   `Temperature (e.g., 30-80)`: シミュレートされた動作温度。
    -   `Error Rate (0.0-1.0)`: モデルの計算エラー率。
-   **出力:**
    入力されたハードウェア指標に基づいて計算された単一の適応度スコアが表示されます。
-   **論理的実装:**
    `run_fitness_evaluation`関数が呼び出されます。`evospikenet.fitness`の`HardwareFitnessEvaluator`を使い、入力されたパラメータから適応度スコアを計算します。

### 4.4. Text Classification (テキスト分類)

-   **目的:**
    訓練済みの`SpikingTransformerClassifier`モデルを使い、入力された文章の感情（ポジティブ/ネガティブ）をリアルタイムで分類します。
-   **パラメータ:**
    -   `Enter a sentence to classify:`: 分類したい英文を入力するテキストエリア。
-   **出力:**
    予測された感情ラベル（`Positive`または`Negative`）と、その予測に対するモデルの確信度がパーセンテージで表示されます。
-   **論理的実装:**
    `run_text_classification`関数が呼び出されます。この関数は、アプリ起動時に`saved_models/`ディレクトリから読み込まれ、メモリ上に保持されている訓練済みモデルと語彙（`vocab.json`）を使用します。入力された文章は、`tokenize_and_pad`関数で単語IDのテンソルに変換され、モデルに入力されます。モデルの出力（ロジット）にソフトマックス関数を適用し、最終的な予測と確信度を計算します。
    **注意:** この機能を利用するには、事前に「コマンドパネル」の「Train Text Classifier」ボタンでモデルを訓練しておく必要があります。

### 4.5. LM Training (Advanced) (LM訓練 - 高度)

-   **目的:**
    `EvoSpikeNetLM`言語モデルを、デフォルトのコーパスだけでなく、Wikipedia、青空文庫、ローカルファイルといった、より実践的で大規模なデータソースから訓練します。このタブは、柔軟な訓練プロセスを実現するための包括的なUIを提供します。
-   **パラメータ:**
    -   `Select Data Source`: 訓練に使用するデータソースを選択します。
        -   `Wikipedia`: 指定したタイトルのWikipedia記事をコーパスとして使用します。下の入力欄に記事のタイトル（例: `人工知能`）を入力します。
        -   `Aozora Bunko`: 青空文庫の作品をコーパスとして使用します。下の入力欄に、作品のHTMLファイルのURLを入力します。
        -   `Local File`: ワークスペースに存在するテキストファイル（`.txt`）をコーパスとして使用します。下の入力欄に、ファイルへのパス（例: `my_corpus.txt`）を入力します。
        -   `Default Corpus`: スクリプト内にハードコードされた小規模なデフォルトコーパスを使用します。
    -   `Epochs`: 訓練を繰り返す回数。
    -   `Learning Rate`: 学習率。モデルのパラメータを更新する際のステップサイズを決定します。
    -   `Block Size`: 一度の訓練で使用するテキストのシーケンス長（トークン数）。
    -   `Batch Size`: 一度のパラメータ更新で使用するシーケンスの数。
-   **操作:**
    1.  パラメータをすべて設定します。
    2.  「Start Advanced Training」ボタンをクリックすると、訓練プロセスがバックグラウンドで開始されます。
    3.  ボタンの下のログ表示エリアに、現在のエポックや損失（Loss）などの進捗がリアルタイムで表示されます。
    4.  訓練が完了すると、`--- Training finished. ---`というメッセージが表示されます。
-   **論理的実装:**
    「Start Advanced Training」ボタンがクリックされると、`frontend/app.py`内の`start_advanced_training`コールバックがトリガーされます。このコールバックは、UIで設定されたパラメータに基づいて`python examples/train_evospikenet_lm.py`を実行するためのコマンドライン引数を組み立てます。訓練スクリプトは`subprocess.Popen`によって非同期で実行され、その標準出力は一時ログファイルにリダイレクトされます。UIは`dcc.Interval`コンポーネントを利用して、このログファイルを定期的にポーリングし、内容をログ表示エリアにストリーミング表示することで、リアルタイムの進捗報告を実現しています。

---

## 5. コマンドパネル

`System & Data`タブには、プロジェクトの管理タスクを実行するためのボタンが配置されています。

-   **Generate Data:**
    -   **実行スクリプト:** `./scripts/run_data_generation.sh`
    -   **目的:** `scripts/generate_spike_data.py`を呼び出し、基本的なSNNシミュレーション用のダミーデータを生成します。（現在は主にデモ用です）
-   **Run CPU Tests:**
    -   **実行スクリプト:** `./scripts/run_tests_cpu.sh`
    -   **目的:** `pytest`を使い、プロジェクト全体のテストスイートをCPUモードで実行します。コードの健全性を確認するために使用します。
-   **Train Text Classifier:**
    -   **実行コマンド:** `python examples/run_text_classification_experiment.py`
    -   **目的:** テキスト分類モデルの訓練を実行します。このコマンドが正常に完了すると、`saved_models/`ディレクトリに訓練済みモデル（`text_classifier.pth`）と語彙ファイル（`vocab.json`）が保存され、「Text Classification」タブの機能が利用可能になります。
-   **Train EvoSpikeNetLM:**
    -   **実行コマンド:** `python examples/train_evospikenet_lm.py`
    -   **目的:** デフォルト設定で`EvoSpikeNetLM`言語モデルの簡易的な訓練を実行します。より詳細なデータソースの選択やパラメータ調整を行いたい場合は、「LM Training (Advanced)」タブを使用してください。
-   **Train Spiking LM (New):**
    -   **実行コマンド:** `python examples/train_spiking_evospikenet_lm.py`
    -   **目的:** 新しく実装された`SpikingEvoSpikeNetLM`モデルの訓練と評価を一度に実行します。訓練完了後、モデルとトークナイザーが`saved_models/`に保存され、続けて評価フェーズが実行されます。
    -   **出力:** 訓練のログに加え、最終的な評価結果として平均損失（Average Loss）と**パープレキシティ（Perplexity）**が表示されます。パープレキシティは言語モデルの性能指標で、値が低いほど、テキストをもっともらしく生成できていることを示します。
-   **Generate Distilled Data (LLM):**
    -   **実行コマンド:** `python examples/generate_distilled_dataset.py`
    -   **目的:** 大規模言語モデル（LLM）を呼び出し、より高品質で多様なテストデータを自動生成します。実行には、環境変数`OPENAI_API_KEY`の設定が必要です。生成されたデータは`distilled_dataset.json`として保存されます。

---

## 6. 高度なワークフロー

### 6.1. ハイパーパラメータ調整

モデルの性能を最大限に引き出すためには、学習率やモデル構造などのハイパーパラメータを調整することが重要です。プロジェクトには、このプロセスを自動化するためのヘルパースクリプトが含まれています。

-   **実行スクリプト:** `./scripts/run_hp_tuning.sh`
-   **目的:** `SpikingEvoSpikeNetLM`モデルのハイパーパラメータチューニングを自動で実行します。
-   **仕組み:**
    1.  スクリプトを開くと、`LEARNING_RATES`や`NUM_BLOCKS`といった配列が定義されています。この配列に、試したいパラメータの値を複数設定します。
    2.  スクリプトを実行すると、これらの値のすべての組み合わせに対して、`examples/train_spiking_evospikenet_lm.py`が順番に呼び出されます。
    3.  各実行の訓練結果（モデルファイルとトークナイザー）は、`saved_models/`ディレクトリ内に、`lr_0.001-blocks_2`のようなパラメータ名を反映したユニークな名前のサブディレクトリが作成され、そこに保存されます。これにより、各実験の結果が上書きされるのを防ぎます。
-   **使い方:**
    1.  `scripts/run_hp_tuning.sh`をテキストエディタで開きます。
    2.  `LEARNING_RATES`や`NUM_BLOCKS`の配列を、試したい値のリストに編集します。
    3.  ターミナルで `./scripts/run_hp_tuning.sh` を実行します。
    4.  各実行のログがコンソールに表示され、完了すると`saved_models/`以下に結果が整理されます。

### 6.2. 学習済みモデルによるテキスト生成

`SpikingEvoSpikeNetLM`の訓練が完了したら、そのモデルを使って新しいテキストを生成（推論）することができます。このために、専用のスクリプトが用意されています。

-   **実行コマンド:** `python examples/run_spiking_lm_generation.py`
-   **目的:** 訓練済みの`SpikingEvoSpikeNetLM`を読み込み、指定されたプロンプト（書き出しの文章）に続くテキストを生成します。
-   **仕組み:**
    1.  スクリプトは、`--run-name`引数で指定されたディレクトリから、訓練済みのモデル（`spiking_lm.pth`）、トークナイザー、およびモデル設定（`model_config.json`）を読み込みます。
    2.  モデル設定に基づき、訓練時と全く同じアーキテクチャのモデルを再構築します。
    3.  `--prompt`で与えられたテキストをトークン化し、モデルの`generate`メソッドに渡してテキスト生成を実行します。
    4.  生成されたトークン列をデコードし、人間が読めるテキストとして出力します。
-   **使い方:**
    ```bash
    # 'my_test_run'という名前で保存されたモデルを使ってテキストを生成する例
    python examples/run_spiking_lm_generation.py \
        --run-name "my_test_run" \
        --prompt "EvoSpikeNet is a framework that" \
        --max-new-tokens 50 \
        --temperature 0.8
    ```
-   **主要な引数:**
    -   `--run-name`: （必須）`saved_models/`内に保存されている、使用したいモデルの実行名（ディレクトリ名）。
    -   `--prompt`: （必須）テキスト生成の開始点となるプロンプト文字列。
    -   `--max-new-tokens`: 生成する新しいトークンの最大数。
    -   `--temperature`: 生成のランダム性を制御します。低い値ほど決定的になり、高い値ほど多様なテキストが生成されやすくなります。
    -   `--top-k`: サンプリングを、最も確率の高い上位K個のトークンに限定します。

---

## 7. コマンドラインでの使用法: スクリプトの実行

`scripts/`ディレクトリには、Dockerコンテナを利用してプロジェクトの各機能を実行するための便利なラッパースクリプトが用意されています。これらのスクリプトは、`docker compose`コマンドを内部で呼び出し、適切な環境（CPUまたはGPU）でコンテナを起動します。

**注意:** これらのスクリプトを実行するには、ローカル環境に`docker`と`docker-compose`がインストールされている必要があります。

### 7.1. テストの実行

-   **スクリプト:**
    -   `./scripts/run_tests_cpu.sh` (CPUモード)
    -   `./scripts/run_tests_gpu.sh` (GPUモード)
-   **目的:** プロジェクト全体のテストスイートを実行し、コードの健全性を確認します。
-   **実行コマンド例:**
    ```bash
    # CPUでテストを実行
    ./scripts/run_tests_cpu.sh
    ```

### 7.2. サンプルアプリケーションの実行

-   **スクリプト:**
    -   `./scripts/run_prod_cpu.sh` (CPUモード)
    -   `./scripts/run_prod_gpu.sh` (GPUモード)
-   **目的:** `example.py`を実行します。これは、`SNNModel`をインスタンス化し、ランダムなスパイクデータを入力して基本的なフォワードパスを実行する、簡単なサンプルです。
-   **実行コマンド例:**
    ```bash
    ./scripts/run_prod_cpu.sh
    ```

### 7.3. フロントエンドの起動

-   **スクリプト:**
    -   `./scripts/run_frontend_cpu.sh` (CPUモード)
    -   `./scripts/run_frontend_gpu.sh` (GPUモード)
-   **目的:** DashベースのWebフロントエンドを起動します。
-   **実行コマンド例:**
    ```bash
    # CPUモードでフロントエンドを起動
    ./scripts/run_frontend_cpu.sh
    ```
-   **アクセス:** サーバーが起動したら、ブラウザで `http://localhost:8050` を開きます。

### 7.4. 開発環境の起動

-   **スクリプト:**
    -   `./scripts/run_dev_cpu.sh` (CPUモード)
    -   `./scripts/run_dev_gpu.sh` (GPUモード)
-   **目的:** プロジェクトのソースコードがマウントされた、インタラクティブな`bash`シェルを起動します。コードの変更やデバッグ、パッケージの追加など、開発作業に利用します。
-   **実行コマンド例:**
    ```bash
    ./scripts/run_dev_cpu.sh
    ```

### 7.5. データ生成とハイパーパラメータ調整

-   **スクリプト:**
    -   `./scripts/run_data_generation.sh`
    -   `./scripts/run_hp_tuning.sh`
-   **目的:**
    -   `run_data_generation.sh`: `scripts/generate_spike_data.py`を呼び出し、ダミーデータを生成します。
    -   `run_hp_tuning.sh`: `SpikingEvoSpikeNetLM`モデルのハイパーパラメータチューニングを自動で実行します。詳細はスクリプト内のコメントを参照してください。

---

## 8. コアコンセプトとアーキテクチャ

このセクションでは、EvoSpikeNetフレームワークの中核をなす主要なコンポーネントの技術的な概念について解説します。

### 8.1. 基本SNNコンポーネント (`evospikenet.core`)

-   **`LIFNeuronLayer`**:
    -   **概要:** Leaky Integrate-and-Fire (LIF) ニューロンの単一レイヤーを実装します。これは、生物学的なニューロンの振る舞いを模倣した、最も基本的なスパイキングニューロンモデルの一つです。
    -   **特徴:**
        -   **整数ベース演算:** パフォーマンスとハードウェアシミュレーションを意識し、膜電位や閾値などの計算はすべて整数で行われます。
        -   **ステートフル:** 各ニューロンは自身の膜電位 (`potential`) を内部状態として保持します。この状態は、`SNNModel`クラスによってシーケンスの開始時にリセットされます。
        -   **エネルギー駆動:** オプションとして`EnergyManager`を受け取り、ニューロンの発火にエネルギーコストを課すことができます。

-   **`SynapseMatrixCSR`**:
    -   **概要:** ニューロン間の接続（シナプス）を、メモリ効率の良い**CSR (Compressed Sparse Row)** 形式のスパース行列として管理します。
    -   **特徴:**
        -   **疎な接続:** 多くのニューロンが互いに接続されていないという、脳の構造を模倣するためにスパース行列が採用されています。
        -   **CPUワークアラウンド:** 現在のPyTorch（バージョン2.x）では、CPU上での整数スパース行列の乗算がサポートされていません。そのため、このクラスのフォワードパスでは、一時的に行列と入力を浮動小数点数に変換して計算し、結果を整数に戻すという回避策が取られています。これはパフォーマンス上の注意点となります。

### 8.2. スパイキングTransformer (`evospikenet.attention`)

-   **`SpikingTransformerBlock`**:
    -   **概要:** 標準的なTransformerブロックを、スパイキングニューロンのコンポーネントで再構築したものです。`SpikingEvoSpikeNetLM`モデルの中核をなします。
    -   **構成要素:**
        -   **`ChronoSpikeAttention`**: ハイブリッドなアテンション機構です。各タイムステップで、入力スパイクを浮動小数点数として扱い、標準的な自己アテンション計算（Scaled Dot-Product Attention）を実行します。その結果をLIFニューロンに通すことで、出力として再びスパイクを生成します。
        -   **`SpikingFFN`**: 2つのLIFニューロン層で構成された、シンプルな全結合のフィードフォワードネットワークです。
    -   **特徴:**
        -   **ハイブリッドアプローチ:** 純粋なSNNでアテンションを計算する複雑さを回避し、実績のある標準的なアテンション計算と、LIFニューロンによる時間的なスパイク処理を組み合わせています。
        -   **簡略化された残差接続:** 標準的なTransformerで用いられるレイヤー正規化（Layer Normalization）は、スパイクのバイナリな性質と相性が悪いため、`torch.clamp(x + ...)`という形で加算とクリッピングによるシンプルな残差接続が実装されています。

### 8.3. モデルアーキテクチャ (`evospikenet.models`)

-   **`SpikingEvoSpikeNetLM`**:
    -   **概要:** このプロジェクトの中核となる、テキスト生成のためのスパイキング言語モデルです。`TASEncoding`（テキストをスパイク列に変換）と`SpikingTransformerBlock`を組み合わせて構成されています。
    -   **特徴:** `AEG`や`MetaSTDP`といった、より高度な自己組織化・学習メカニズムと連携して動作するように設計されています。

-   **`MultiModalEvoSpikeNetLM`**:
    -   **概要:** テキストと画像の両方を入力として受け取ることができる、マルチモーダルなスパイキング言語モデルです。
    -   **アーキテクチャ:**
        1.  **エンコーディング:** `TASEncoding`でテキストを、`SpikingVisionEncoder`（畳み込みSNN）で画像を、それぞれスパイク列に変換します。
        2.  **特徴量融合:** 画像全体から得られたスパイク特徴量を、テキストの各トークンに対応するスパイク列にブロードキャスト（拡張）し、特徴量次元で結合します。
        3.  **融合層:** 結合された特徴量を、線形層とLIFニューロン層（`fusion_lif`）で処理し、単一の融合されたスパイク列を生成します。
        4.  **処理:** 融合されたスパイク列を、複数の`SpikingTransformerBlock`に通して、文脈情報を処理します。
        5.  **デコーディング:** 最終的な出力スパイクを時間方向に積分し、線形層を通して語彙のロジット（確率分布）に変換することで、次のトークンを予測します。

### 8.4. マルチモーダルモデルの現状と使い方

`MultiModalEvoSpikeNetLM`は、テキストと画像の両方を入力として処理できる、より高度なモデルとして設計されています。

-   **アーキテクチャ:**
    -   モデルのアーキテクチャに関する詳細な説明は、前のセクション `8.3. モデルアーキテクチャ` を参照してください。

-   **現在の実装状況とデモンストレーション:**
    -   モデルのアーキテクチャは完全に実装されており、テスト済みです。
    -   `examples/train_multi_modal_lm.py` という、モデルの動作を検証するためのデモンストレーション用スクリプトが提供されています。
    -   **重要:** このスクリプトは、ランダムに生成された**ダミーの画像とテキストデータ**を使用して、モデルの学習プロセス（順伝播・逆伝播）がエラーなく実行できることを示すためのものです。**実際の画像・テキストファイルを読み込んで学習したり、学習済みモデルを保存したりする機能はまだ実装されていません。**

-   **実行方法（デモ）:**
    ```bash
    # デモスクリプトを実行
    python examples/train_multi_modal_lm.py --epochs 3
    ```
    このコマンドは、ダミーデータでモデルを3エポック訓練し、各エポックの平均損失を表示します。

-   **今後の展望:**
    -   実世界のデータセット（例: 画像キャプションデータなど）を読み込むためのデータローダーの実装。
    -   学習済みモデルを保存・読み込みする機能の追加。
    -   画像とプロンプトを入力として、条件付きでテキストを生成する推論スクリプトの開発。

    これらの機能は、今後の開発課題となります。
