# Copyright 2025 Moonlight Technologies Inc.. All Rights Reserved.
# Auth Masahiro Aoki

# EvoSpikeNet: 主要な概念

このドキュメントは、EvoSpikeNetフレームワークの中核をなす、より高度でユニークな概念について技術的な詳細を解説します。

---

## 1. 制御システム (`evospikenet/control.py`)

`evospikenet.control`モジュールは、SNNの学習と動作を外部のメタレベルから制御するためのメカニズムを提供します。

### 1.1. MetaSTDP (メタ学習による可塑性制御)

`MetaSTDP`クラスは、モデル全体の性能（報酬信号として与えられる）に基づいて、全ニューロンの学習関連パラメータを動的に調整する、一種のメタ学習エージェントとして機能します。

#### 動作原理
1.  **ターゲットパラメータ:** 現在の実装では、モデル内に存在する全ての`snn.Leaky`（LIFニューロン）層の**膜電位の減衰率 (`beta`)** を調整対象とします。`beta`はニューロンの「記憶」の長さを決定する重要なパラメータです（1に近いほど長く記憶する）。
2.  **報酬ベースの更新:**
    -   訓練の各ステップで、損失（loss）などから計算された報酬（reward）が`update`メソッドに渡されます。
    -   `MetaSTDP`は、内部で報酬のベースライン（期待値の移動平均）を保持しています。
    -   現在の報酬がベースラインを上回れば（つまり損失が期待より小さければ）、`beta`を`1`に近づける（記憶を長くする）方向に更新します。
    -   逆に、報酬がベースラインを下回れば、`beta`を小さくする（記憶を短くする）方向に更新します。
3.  **学習率のアニーリング:**
    -   `MetaSTDP`は、それ自体の学習率（`eta`）を持っています。この`eta`は、`beta`をどれだけ大きく変化させるかを決定します。
    -   学習が安定するように、`update`メソッドが呼び出されるたびに、この`eta`はわずかに減衰（アニーリング）します。これにより、学習初期は`beta`が大きく変動し、学習が進むにつれて変動が小さくなり、安定した状態に収束しやすくなります。

このメカニズムにより、モデルは自身の全体的な性能を見ながら、ニューロンの基本的な性質を自己調整していくことが可能になります。

### 1.2. AEG (Activity-driven Energy Gating)

`AEG`クラスは、ニューロン群の活動に応じてエネルギーを動的に管理するメカニズムです。

#### 動作原理
1.  **エネルギーの概念:** 各ニューロン（またはニューロン群）は、内部的な「エネルギー」レベルを保持しています。このエネルギーは`255`（最大）から`0`まで変動します。
2.  **発火による消費:** ニューロンが発火（スパイク）すると、そのエネルギーは`consumption_rate`に基づいて減少します。この消費量は、各スパイクの「重要度（`importance`）」によって重み付けされます。これにより、重要度の低い情報に対する発火はエネルギーコストが高くなり、抑制されやすくなります。
3.  **エネルギーによる発火抑制（ゲーティング）:** ニューロンのエネルギーが一定の閾値（`threshold`）を下回ると、そのニューロンは一時的に発火できなくなります。たとえ膜電位が発火閾値を超えても、スパイクは出力されません（ゲートされます）。
4.  **報酬によるエネルギー供給:** `supply`メソッドを通じて、外部から報酬（reward）信号が与えられると、全ニューロンのエネルギーレベルが`supply_rate`に基づいて回復します。

この仕組みにより、ネットワークはエネルギーというリソースを効率的に使い、重要度の高い情報処理に集中するよう自己調整することが期待されます。これは、`SpikingEvoSpikeNetLM`モデルで、不要なスパイクを抑制し、計算効率を高めるために利用されています。
