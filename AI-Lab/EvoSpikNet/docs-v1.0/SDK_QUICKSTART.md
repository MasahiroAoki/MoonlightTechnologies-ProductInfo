<!-- Reviewed against source: 2025-12-21. English translation pending. -->
# Copyright 2025 Moonlight Technologies Inc. All Rights Reserved.
# Auth Masahiro Aoki

# EvoSpikeNet SDK ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰

**æœ€çµ‚æ›´æ–°æ—¥:** 2025å¹´12æœˆ15æ—¥
**30ç§’ã§å§‹ã‚ã‚‹EvoSpikeNet SDK**

## ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç›®çš„ã¨ä½¿ã„æ–¹
- ç›®çš„: SDKã‚’æœ€çŸ­ã§ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã€APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å‹•ã‹ã™æ‰‹é †ã‚’ç¤ºã™ã€‚
- å¯¾è±¡èª­è€…: SDKåˆ©ç”¨ã‚’é–‹å§‹ã™ã‚‹é–‹ç™ºè€…ã€‚
- ã¾ãšèª­ã‚€é †: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« â†’ APIã‚µãƒ¼ãƒãƒ¼èµ·å‹• â†’ æœ€å°é™ã®ä½¿ç”¨ä¾‹ã€‚
- é–¢é€£ãƒªãƒ³ã‚¯: åˆ†æ•£è„³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ `examples/run_zenoh_distributed_brain.py`ï¼ˆå‹•ä½œç¢ºèªç’°å¢ƒã¨ã—ã¦ï¼‰ã€PFC/Zenoh/Executiveè©³ç´°ã¯ [implementation/PFC_ZENOH_EXECUTIVE.md](implementation/PFC_ZENOH_EXECUTIVE.md)ã€‚
- å®Ÿè£…ãƒãƒ¼ãƒˆï¼ˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼‰: `docs/implementation/ARTIFACT_MANIFESTS.md` â€” `artifact_manifest.json` ã¨ CLI ãƒ•ãƒ©ã‚°ã®ä»•æ§˜ï¼ˆ`--artifact-name` / `--precision` / `--quantize` / `--privacy-level` / `--node-type`ï¼‰ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install -e .
```

## APIã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•

```bash
sudo ./scripts/run_api_server.sh
```

## æœ€å°é™ã®ä½¿ç”¨ä¾‹

```python
from evospikenet.sdk import EvoSpikeNetAPIClient

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = EvoSpikeNetAPIClient()

# ã‚µãƒ¼ãƒãƒ¼ã®ç¢ºèª
if client.wait_for_server():
    # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
    result = client.generate("äººå·¥çŸ¥èƒ½ã¨ã¯")
    print(result['generated_text'])
```

---

## ã‚ˆãä½¿ã†ãƒ‘ã‚¿ãƒ¼ãƒ³

### 1ï¸âƒ£ ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ

```python
from evospikenet.sdk import EvoSpikeNetAPIClient

client = EvoSpikeNetAPIClient()
result = client.generate("æ©Ÿæ¢°å­¦ç¿’ã®å¿œç”¨ä¾‹ã‚’5ã¤åˆ—æŒ™ã—ã¦ãã ã•ã„")
print(result['generated_text'])
```

### 2ï¸âƒ£ è¤‡æ•°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å‡¦ç†

```python
prompts = ["What is AI?", "Explain machine learning", "Deep learning basics"]
results = client.batch_generate(prompts, max_length=100)

for prompt, result in zip(prompts, results):
    print(f"{prompt}: {result.get('generated_text', 'Failed')}")
```

### 3ï¸âƒ£ ç”»åƒã‚’å«ã‚€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å‡¦ç†

```python
response = client.submit_prompt(
    prompt="ã“ã®ç”»åƒã«å†™ã£ã¦ã„ã‚‹ã‚‚ã®ã¯ä½•ã§ã™ã‹ï¼Ÿ",
    image_path="./image.jpg"
)
result = client.poll_for_result(timeout=60)
print(result['response'])
```

### 4ï¸âƒ£ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãå®Ÿè¡Œ

```python
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¤œè¨¼
if client.validate_prompt("ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"):
    # è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ä»˜ãã§å®Ÿè¡Œ
    result = client.with_error_handling(
        client.generate,
        prompt="ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
        max_length=100,
        retries=3
    )
    if result:
        print("æˆåŠŸ:", result['generated_text'])
```

### 5ï¸âƒ£ éåŒæœŸã‚¿ã‚¹ã‚¯ã®ç›£è¦–

```python
# ã‚¿ã‚¹ã‚¯é€ä¿¡
client.submit_prompt(prompt="è¤‡é›‘ãªã‚¿ã‚¹ã‚¯")

# çµæœã‚’ãƒãƒ¼ãƒªãƒ³ã‚°
result = client.poll_for_result(timeout=120, interval=5)

if result:
    print("çµæœ:", result['response'])
else:
    print("ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
```

### 6ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã¨å¾©å…ƒ

```python
import torch
import io

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
session = client.create_log_session("ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Ÿé¨“")
session_id = session['session_id']

# ãƒ¢ãƒ‡ãƒ«ä¿å­˜
model_buffer = io.BytesIO()
torch.save(model.state_dict(), model_buffer)
model_buffer.seek(0)

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
artifact = client.upload_artifact(
    session_id=session_id,
    artifact_type="model",
    name="model.pth",
    file=model_buffer
)

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
client.download_artifact(
    artifact_id=artifact['artifact_id'],
    destination_path="./downloaded_model.pth"
)
```

### 7ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

```python
import zipfile
import os

# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™
data_dir = "./training_data"
os.makedirs(f"{data_dir}/images", exist_ok=True)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ZIPåœ§ç¸®
zip_buffer = io.BytesIO()
with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
    # CSVãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ 
    zf.write(f"{data_dir}/captions.csv", arcname='captions.csv')
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«è¿½åŠ 
    for root, _, files in os.walk(f"{data_dir}/images"):
        for file in files:
            full_path = os.path.join(root, file)
            archive_name = os.path.join('images', os.path.relpath(full_path, f"{data_dir}/images"))
            zf.write(full_path, arcname=archive_name)

zip_buffer.seek(0)
zip_buffer.name = "training_dataset.zip"

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
dataset_artifact = client.upload_artifact(
    session_id=session_id,
    artifact_type="dataset",
    name="vision_training_data",
    file=zip_buffer,
    llm_type="SpikingEvoMultiModalLM"
)

print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {dataset_artifact['artifact_id']}")
```

---

## ã‚µãƒ¼ãƒãƒ¼æƒ…å ±ã®ç¢ºèª

```python
# ã‚µãƒ¼ãƒãƒ¼ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
is_healthy = client.is_server_healthy()
print(f"ã‚µãƒ¼ãƒãƒ¼ã¯æ­£å¸¸ã§ã™ã‹ï¼Ÿ: {'ã¯ã„' if is_healthy else 'ã„ã„ãˆ'}")

# ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç›£è¦–
status = client.get_simulation_status()
print(f"ç¾åœ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status.get('last_prompt_status', 'N/A')}")
print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ¼ãƒ‰æ•°: {len(status.get('nodes', []))}")
```

---

## ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºæ–¹æ³•

| ã‚¨ãƒ©ãƒ¼ | åŸå›  | è§£æ±ºç­– |
|-------|------|------|
| `ConnectionError` | APIã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ãªã„ | `sudo ./scripts/run_api_server.sh` ã§èµ·å‹• |
| `Timeout` | å‡¦ç†ãŒé…ã„ | `timeout`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ |
| `Invalid prompt` | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæ¡ä»¶ã‚’æº€ãŸã•ãªã„ | `validate_prompt()`ã§äº‹å‰ç¢ºèª |

---

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

- ğŸ“– [å®Œå…¨ãªSDKãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](./EvoSpikeNet_SDK.md)ã‚’èª­ã‚€
- ğŸ“ [ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰](./docs/sdk/)ã‚’ç¢ºèªã™ã‚‹
- ğŸ”§ [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](./EvoSpikeNet_SDK.md#11-ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)ã‚’å‚ç…§ã™ã‚‹
- ğŸ’¬ GitHub Issuesã§è³ªå•ã™ã‚‹

---

## é«˜åº¦ãªæ©Ÿèƒ½ (P3å®Ÿè£…å®Œäº†)

### ğŸ”„ é…å»¶ç›£è¦–ã¨æœ€é©åŒ–

```python
# é…å»¶çµ±è¨ˆã®å–å¾—
latency_stats = client.get_latency_stats()
print(f"å¹³å‡é…å»¶: {latency_stats['mean']:.2f}ms")
print(f"95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: {latency_stats['p95']:.2f}ms")

# é…å»¶ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ç¢ºèª
target_met = client.check_latency_target(500.0)  # 500msç›®æ¨™
print(f"é…å»¶ç›®æ¨™é”æˆ: {target_met}")
```

### ğŸ’¾ ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ/å¾©æ—§

```python
# ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ
snapshot_result = client.create_snapshot(
    snapshot_name="backup_20251212",
    include_models=True,
    include_data=True
)

# ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¸€è¦§
snapshots = client.list_snapshots()

# ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§
restore_result = client.restore_snapshot(
    snapshot_path="/path/to/snapshot.gz",
    restore_models=True,
    restore_data=True
)
```

### ğŸ“Š ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ

```python
# ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
test_result = client.run_scalability_test(
    max_nodes=1000,
    test_duration=300.0,
    load_pattern="linear"
)

# ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³å–å¾—
resources = client.get_resource_usage()
print(f"CPUä½¿ç”¨ç‡: {resources['cpu_usage']}%")
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {resources['memory_usage']}MB")
```

### ğŸ”§ ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ–

```python
# ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ–ï¼ˆONNX/é‡å­åŒ–ãªã©ï¼‰
optimization_result = client.optimize_model(
    model_type="vision",              # "vision" | "audio"
    optimizations=["onnx", "quantize"]
)

# ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
benchmark_result = client.benchmark_model(
    model_type="vision",
    num_runs=50
)
```

### ğŸ›¡ï¸ é«˜å¯ç”¨æ€§ç›£è¦–

```python
# å¯ç”¨æ€§ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—
availability = client.get_availability_status()
print(f"å…¨ä½“å¯ç”¨æ€§: {availability['overall_availability']}%")
print(f"ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ : {availability['uptime_percentage']}%")

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
health_result = client.perform_health_check()

# å¯ç”¨æ€§çµ±è¨ˆå–å¾—
stats = client.get_availability_stats(time_window="24h")
```

### ğŸŒ éåŒæœŸZenohé€šä¿¡

```python
# Zenohé€šä¿¡çµ±è¨ˆå–å¾—
zenoh_stats = client.get_zenoh_stats()
print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {zenoh_stats['messages_sent']}")
print(f"å¹³å‡é…å»¶: {zenoh_stats['avg_latency']}ms")
```

### âš–ï¸ åˆ†æ•£ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹

```python
# ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ææ¡ˆ
proposal_result = client.propose_consensus_decision(
    decision_type="resource_allocation",
    payload={"resource": "gpu", "amount": 50},
    priority=1
)

# ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹çµæœå–å¾—
result = client.get_consensus_result(proposal_result['proposal_id'])

# ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹çµ±è¨ˆ
consensus_stats = client.get_consensus_stats()
```

---

## ãƒãƒ¼ãƒˆã‚·ãƒ¼ãƒˆ

```python
from evospikenet.sdk import EvoSpikeNetAPIClient

client = EvoSpikeNetAPIClient()

# ã‚µãƒ¼ãƒãƒ¼ç¢ºèª
client.wait_for_server()           # èµ·å‹•å¾…æ©Ÿ
client.is_server_healthy()         # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

# ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
client.generate(prompt)            # ã‚·ãƒ³ãƒ—ãƒ«ç”Ÿæˆ
client.batch_generate(prompts)     # ãƒãƒƒãƒå‡¦ç†
client.submit_prompt(prompt)       # éåŒæœŸé€ä¿¡
client.poll_for_result()           # çµæœå¾…æ©Ÿ

# æ¤œè¨¼ãƒ»åˆ¶å¾¡
client.validate_prompt(prompt)     # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¤œè¨¼
client.with_error_handling(func)   # ãƒªãƒˆãƒ©ã‚¤ä»˜ãå®Ÿè¡Œ

# ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ»ãƒ­ã‚°
client.get_simulation_status()     # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—
client.get_simulation_result()     # çµæœå–å¾—
client.get_remote_log()            # ãƒ­ã‚°å–å¾—

# ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç®¡ç†
client.create_log_session()        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
client.upload_artifact()           # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
client.download_artifact()         # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
client.list_artifacts()            # ãƒªã‚¹ãƒˆè¡¨ç¤º
```

## 6ï¸âƒ£ LLMãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®å®Ÿè¡Œ (æ–°æ©Ÿèƒ½)

### Vision Encoderãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

```python
from evospikenet.sdk import EvoSpikeNetAPIClient

client = EvoSpikeNetAPIClient()

# Vision Encoderãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®é€ä¿¡
job_data = {
    "category": "Vision",
    "model_name": "google/vit-base-patch16-224",
    "dataset_path": "data/llm_training/Vision/vision_data.jsonl",
    "output_dir": "saved_models/Vision/vision-training-run",
    "gpu": True,
    "epochs": 3,
    "batch_size": 8,
    "learning_rate": 0.00001
}

response = client.submit_training_job(job_data)
print(f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹ã—ã¾ã—ãŸ: {response['job_id']}")

# ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ç¢ºèª
status = client.get_training_status(response['job_id'])
print(f"ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status['status']}")
```

### Audio Encoderãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

```python
# Audio Encoderãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®é€ä¿¡
job_data = {
    "category": "Audio",
    "model_name": "openai/whisper-base",
    "dataset_path": "data/llm_training/Audio/audio_data.jsonl",
    "output_dir": "saved_models/Audio/audio-training-run",
    "gpu": True,
    "epochs": 3,
    "batch_size": 8,
    "learning_rate": 0.00001
}

response = client.submit_training_job(job_data)
print(f"Audioãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹ã—ã¾ã—ãŸ: {response['job_id']}")
```

### ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®ç›£è¦–

```python
# ã™ã¹ã¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®ãƒªã‚¹ãƒˆã‚’å–å¾—
jobs = client.list_training_jobs()
for job in jobs:
    print(f"ã‚¸ãƒ§ãƒ–ID: {job['job_id']}, ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {job['status']}, ã‚«ãƒ†ã‚´ãƒª: {job['category']}")

# ç‰¹å®šã®ã‚¸ãƒ§ãƒ–ã®è©³ç´°ã‚’å–å¾—
job_details = client.get_training_job_details("vision_training_job_001")
print(f"ã‚¸ãƒ§ãƒ–è©³ç´°: {job_details}")
```

### åˆ†æ•£è„³ãƒãƒ¼ãƒ‰å¯¾å¿œãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

```python
# åˆ†æ•£è„³ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
node_configs = {
    "Vision": {
        "model_name": "google/vit-base-patch16-224",
        "node_types": ["Vision-Primary", "Vision-Secondary"]
    },
    "Audio": {
        "model_name": "openai/whisper-base", 
        "node_types": ["Audio-Primary", "Audio-Secondary"]
    },
    "LangText": {
        "model_name": "microsoft/DialoGPT-medium",
        "node_types": ["Lang-Primary", "Lang-Secondary"]
    }
}

# Visionãƒãƒ¼ãƒ‰ç”¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–
vision_job = {
    "category": "Vision",
    "model_name": node_configs["Vision"]["model_name"],
    "dataset_path": "data/llm_training/Vision/vision_data.jsonl",
    "output_dir": "saved_models/Vision/distributed-vision-run",
    "gpu": True,
    "epochs": 5,
    "batch_size": 16,
    "learning_rate": 0.00002
}

client.submit_training_job(vision_job)
```

Happy coding! ğŸš€
