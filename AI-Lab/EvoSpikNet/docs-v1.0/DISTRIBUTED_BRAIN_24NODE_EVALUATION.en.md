````markdown
<!-- Reviewed against source: 2025-12-21. English translation completed. -->
<!-- Copyright: 2025 Moonlight Technologies Inc. All Rights Reserved. -->
<!-- Author: Masahiro Aoki -->

# 24-Node Configuration Validation Report

Created: December 21, 2025

## Overview
- Target: Validation of the feasibility of the "24-node full brain" configuration in distributed brain simulation
- Conducted: Short-duration simulation (24 nodes, 5 seconds) using scalability testing in the repository (`evospikenet.scalability_test.ScalabilityTester`) and code review

> Implementation Note (Artifacts): For model artifacts generated by simulations or tests and `artifact_manifest.json` specifications, refer to `docs/implementation/ARTIFACT_MANIFESTS.md`.

## Lightweight Simulation Results Summary (Executed)
```json
{"num_nodes":24,
 "duration":5.081160306930542,
 "metrics":{
   "throughput":2.4956167570360264,
   "avg_latency":400.7025506543207,
   "max_latency":1357.4155449896352,
   "cpu_usage":4.766666666666667,
   "memory_usage":36.03333333333333,
   "errors":0
 }
}
```

Note: The above is a short-duration synthetic simulation result and does not reflect production-level load/model weights/I/O requirements. Full evaluation requires re-testing with long-duration real workloads.

## Major Issues Identified in Code Review
- Threshold calculation in `DistributedMotorConsensus._determine_consensus`:
  - Current: `required_votes = int(self.num_nodes * self.consensus_threshold)` (floor truncation)
  - Problem: Truncation may result in actual quorum being lower than expected (e.g., 24 * 0.67 = 16.08 → int → 16). In operation, `math.ceil` should be used for safety.

## Feasibility Assessment (Design Perspective)
- Functional Coverage: 24 nodes are suitable for small to medium-scale distributed brain experiments. Each role can be assigned to cover observation → encoding → inference → decision-making → memory/learning.
- Redundancy: Always redundant single points of failure (aggregator, vector DB, federator, etc.). Multiple instances (mirrors) are recommended for critical nodes.
- Consensus: Consensus algorithms depend on node count, so strict quorum calculation is essential (use ceil, or explicit threshold setting).
- Resource Allocation: Assign GPUs to inference/encoders, dedicated storage (Milvus/DB) to memory nodes, high-throughput bandwidth and checkpoint areas to learning nodes.
- Network: Use low-latency networks (10GbE or higher assumed) and perform bandwidth management.
- Security: Apply strong authentication (API keys/TLS/RBAC) and audit logs to sensitive data/control commands.

## Recommended Configuration (24-Node Example)
Distribution plan for total 24 nodes across the following roles (considering use case and redundancy):

- Sensing Nodes: 4
- Encoder Nodes: 4
- Inference/LM Nodes: 6
- Planning/Controller Nodes: 2
- Memory Nodes (Vector DB/Retriever): 3
- Learning Nodes (Trainer/Updater): 1
- Aggregation/Mediation Nodes (Aggregator/Federator): 2
- Management/Utility Nodes (Monitoring/Auth/Logging): 2

This distribution can be adjusted based on use case. For example, increase sensing/encoders for vision-focused systems, or increase inference nodes for language-focused systems.

## Recommended Immediate Actions
1. Change `int(...)` to `math.ceil(...)` in `DistributedMotorConsensus._determine_consensus` to correct quorum to the safe side.
2. Execute `ScalabilityTester.run_full_scalability_test` with production-like load (real models/I/O) to obtain throughput/latency/error conditions for 24 nodes.
3. Introduce redundancy configuration and monitoring for critical services (vector DB, aggregator, auth, storage) (explicitly specify replica counts).
4. Document resource requirements per node (CPU/GPU/memory/network) and create deployment plans.

## Next Steps (Proposal)
- Execute full testing (`run_full_scalability_test`) and append results to this document.
- The recommended fixes above (quorum calculation) can be committed/PR created as patches. Should I apply them?
````

