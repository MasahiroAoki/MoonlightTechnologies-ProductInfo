# Copyright 2025 Moonlight Technologies Inc. All Rights Reserved.
# Auth Masahiro Aoki

# EvoSpikeNet: 主要な概念と技術詳細

**最終更新日:** 2025年12月7日

このドキュメントでは、EvoSpikeNetフレームワークの中核をなす、より高度でユニークな概念に関する技術的な詳細を説明します。ソースコードに基づく数式、アーキテクチャ図、実装詳細を含みます。

---

## 目次

1. [スパイキングニューラルネットワークの基礎](#1-スパイキングニューラルネットワークの基礎)
2. [ChronoSpikeAttention: 因果的時間アテンション機構](#2-chronospikeattention-因果的時間アテンション機構)
3. [量子変調PFCフィードバックループ](#3-量子変調pfcフィードバックループ)
4. [マルチモーダル・センサーフュージョン・パイプライン](#4-マルチモーダルセンサーフュージョンパイプライン)
5. [運動野学習パイプライン](#5-運動野学習パイプライン)
6. [現行アーキテクチャ: Zenohによる非同期通信](#6-現行アーキテクチャ-zenohによる非同期通信)
7. [その他の主要な概念](#7-その他の主要な概念)

---

---

## 1. スパイキングニューラルネットワークの基礎

EvoSpikeNetは、生物学的な神経細胞の動作を模倣する**スパイキングニューラルネットワーク (SNN)** を中核技術として採用しています。従来の人工ニューラルネットワークが連続値を扱うのに対し、SNNは時間的に離散的な**スパイク (spike)** と呼ばれる0/1のイベントで情報を伝達します。

### 1.1. LIF (Leaky Integrate-and-Fire) ニューロン

本フレームワークの基本となるニューロンモデルは、計算効率に優れた **LIFNeuronLayer** (`evospikenet/core.py`) です。整数演算を使用した実装により、組み込みデバイスやFPGAへの展開が容易です。

#### 数理モデル

LIFニューロンの膜電位 $V(t)$ は以下の漏れ統合ダイナミクスに従います：

$$
V(t+1) = V(t) \cdot \frac{\text{leak}}{256} + I_{\text{syn}}(t)
$$

ここで：
- $V(t)$: 時刻 $t$ における膜電位 (16bit整数)
- $\text{leak}$: リーク係数 (デフォルト230、約0.9の減衰に相当)
- $I_{\text{syn}}(t)$: シナプス入力電流
- スパイク発火条件: $V(t) \geq \theta$ (閾値 $\theta$ はデフォルト1024)
- 発火後、$V(t)$ はリセット電位 (デフォルト0) に戻る

#### 実装コード (`evospikenet/core.py`)

```python
# 整数演算によるリーク処理（オーバーフロー防止のため32bit中間計算）
potential_32 = (potential_32 * leak_32) // 256

# シナプス入力の統合
potential_32 = potential_32 + synaptic_input.to(torch.int32)

# 16bit範囲にクランプ
self.potential = torch.clamp(potential_32, -32768, 32767).to(torch.int16)

# 閾値判定とスパイク生成
spikes = (self.potential >= self.threshold).to(torch.int8)
self.potential[spikes.bool()] = self.reset_potential  # リセット
```

### 1.2. Izhikevich ニューロン

生物学的妥当性を重視する場合、**IzhikevichNeuronLayer** (`evospikenet/core.py`) を使用できます。このモデルは、わずか4つのパラメータで、Regular Spiking、Fast Spiking、Burstingなど、多様なニューロン発火パターンを再現可能です。

#### 数理モデル

Izhikevichモデルは2変数の微分方程式で表現されます：

$$
\frac{dv}{dt} = 0.04v^2 + 5v + 140 - u + I
$$

$$
\frac{du}{dt} = a(bv - u)
$$

発火条件: $v \geq 30 \text{ mV}$ のとき、$v \leftarrow c$、$u \leftarrow u + d$

パラメータ：
- $a$: 回復変数 $u$ の時定数 (デフォルト0.02)
- $b$: 膜電位 $v$ に対する $u$ の感度 (デフォルト0.2)
- $c$: リセット電位 (デフォルト-65 mV)
- $d$: リセット後の $u$ の増加量 (デフォルト8)

#### 実装コード (`evospikenet/core.py`)

```python
# 勾配を伝播可能な代理関数を使用したスパイク生成
spikes = self.spike_grad(self.v - 30.0)

# 条件付き更新（スパイク発火時のリセット処理）
spiked_mask = spikes > 0
v_after_spike = torch.where(spiked_mask, self.c, self.v)
u_after_spike = torch.where(spiked_mask, self.u + self.d, self.u)

# オイラー法による数値積分
dv = (0.04 * v_after_spike**2 + 5 * v_after_spike + 140 - u_after_spike + I)
du = self.a * (self.b * v_after_spike - u_after_spike)

self.v = v_after_spike + self.dt * dv
self.u = u_after_spike + self.dt * du
```

### 1.3. ニューロンモデルの比較

| モデル | 計算量 | 生物学的妥当性 | 勾配学習 | 用途 |
|--------|--------|----------------|----------|------|
| **LIFNeuronLayer** | 極小 | 低 | ✓ | エッジデバイス、大規模シミュレーション |
| **IzhikevichNeuronLayer** | 中 | 高 | ✓ | 神経科学研究、リアルな発火パターン再現 |
| **snnTorch Leaky** | 小 | 中 | ✓ | 標準的なSNN学習タスク |

---

本フレームワークは、多種多様なセンサーからのデータを統合し、PFC（前頭前野）が行動を決定するための統一された「世界理解」を生成するよう設計されています。これは標準化されたパイプラインによって実現されます。

### 1.1. コアデータ構造: `SpikePacket` (`evospikenet/structures.py`)
すべてのセンサーデータは、統一された`SpikePacket`形式に変換されます。このデータクラスにより、視覚、LiDAR、力覚など、あらゆるモダリティからの情報が、一貫性があり、タイムスタンプが付与され、メタデータが豊富な構造で脳内を伝達されることが保証されます。

```python
@dataclass
class SpikePacket:
    timestamp: float           # ハードウェアタイムスタンプ（ns）
    modality: str              # "vision", "lidar", "force" など
    data: torch.Tensor         # スパイク列 [ニューロン数, タイムステップ数]
    metadata: dict             # カメラID, バウンディングボックスなど
```

### 1.2. センサー前処理 (`evospikenet/preprocessing.py`)
専門の前処理クラスが、生のセンサー入力を`SpikePacket`オブジェクトに変換します。これらのクラスは、効率的なリアルタイム特徴抽出のために、専用のスパイクベース・ニューラルネットワークを多用します。
- **`VisionPreprocessor`**: `SpikeEdgeDetector`と`SpikeYOLOv8`を用いて、カメラフレームからエッジと物体情報を抽出します。
- **`LidarPreprocessor`**: `VoxelSpikeEncoder`を用いて、3D点群をスパースなスパイク表現に変換します。
- **`ForcePreprocessor`**: 力・トルクセンサーの急激な変化をスパイクイベントに変換します。

### 1.3. マルチモーダル統合 (`evospikenet/fusion.py`)
`MultimodalFusion`モジュールは、知覚システムの心臓部です。すべてのアクティブなセンサーから`SpikePacket`オブジェクトを受け取り、2つの主要な処理を実行します：
1.  **射影**: 各モダリティのデータは、モダリティ固有の線形層を通過し、共通の次元空間に射影されます。
2.  **時間的統合**: 統一された特徴量は、`ChronoSpikeAttention`によって処理されます。これにより、時間を通じてさまざまな感覚入力の重要度が重み付けされ、単一の統合された環境表現が生成されます。この最終的なテンソルが、PFCの「世界理解」を構成します。

---

## 2. 運動野学習パイプライン (`frontend/pages/motor_cortex.py`)

運動野システムは、単に命令を実行するだけでなく、専用UIを介して管理される高度な4段階のパイプラインを通じて学習し、適応するように設計されています。

-   **ステージ1: 模倣学習 (Behavior Cloning)**: 人間のオペレーターによる短いデモンストレーション（例：5分間）を提供することで、新しいスキルが初期化されます。モデルはこの動作を完全に模倣することを学習しますが、適応性はありません。
-   **ステージ2: 実世界強化学習**: ロボットは自己改善フェーズに入り、タスクを何百回も実行します。`SpikePPO`を使用し、人間の望む結果をモデル化した報酬関数に基づいて、成功、速度、滑らかさ（優しさ）を最適化し、初期ポリシーを洗練させます。
-   **ステージ3: ゼロショット汎化**: `WorldModel`（DreamerV3など）を活用し、エージェントは明示的に訓練されていない全く新しいタスクに挑戦し、しばしば数回の試行で成功します。
-   **ステージ4: 人間との協調**: 最終形態では、エージェントは協調モードに入り、力覚センサーのデータを用いて人間の意図を推定し、歩行やリハビリテーションなどのタスクを安全に支援します。

このパイプライン全体は、Webインターフェースから制御および監視されるマスタースクリプト`evo_motor_master.py`によって編成されます。

---

## 3. 現行アーキテクチャ: Zenohによる非同期通信

分散脳アーキテクチャは、同期的な`torch.distributed`モデルから、**Zenoh**を用いた完全な非同期・分散型アーキテクチャへと移行しました。これにより、システムの堅牢性、スケーラビリティ、リアルタイム性が大幅に向上しています。

-   **非同期Pub/Sub**: すべてのノード間通信は、Zenohを介したPublish/Subscribeモデルで行われます。これにより、マスター/スレーブ型のボトルネックが解消され、各モジュールが独立して動作できるようになりました。プロンプトはAPIからZenohの`evospikenet/api/prompt`トピックにpublishされ、関心のあるモジュールがこれをsubscribeします。
-   **分散協調**: 階層的な制御は維持しつつも、通信の失敗がシステム全体の停止に繋がらない、より柔軟な構造になりました。
-   **実装**: この新しいアーキテクチャは`examples/run_zenoh_distributed_brain.py`スクリプトによって実装されています。UIから呼び出される`run_distributed_brain_simulation.py`は、後方互換性のために残されたラッパーであり、その内容は非推奨となった`torch.distributed`ベースの古い実装コードそのものです。
-   **堅牢性と速度**: この変更は、現実世界の量産ロボットに求められる、真に堅牢でスケーラブル、かつ高速起動が可能なシステムを構築するための重要なステップです。

---

## 4. 旧アーキテクチャ: `torch.distributed`

（参考情報として、旧アーキテクチャの概要を以下に示します）

旧アーキテクチャは、`torch.distributed`を使用して個別のプロセスとして実行される専門化された「機能モジュール」を、中央の「前頭前野（PFC）モジュール」が調整する、マスター/スレーブ型のモデルを採用していました。

-   **マスタープロセス (Rank 0): PFCモジュール**: APIから高レベルの目標を受け取り、それを解釈して適切なスレーブモジュールにタスクをディスパッチしていました。
-   **スレーブプロセス (Rank > 0): 機能モジュール**: 視覚、言語、運動などのタスクの専門家ノードでした。
-   **通信**: `torch.distributed`の同期的な`send`/`recv`操作に依存しており、これがパフォーマンスのボトルネックや単一障害点となる可能性がありました。

---

## 5. その他の主要な概念

- **`SpikingEvoSpikeNetLM`**: TransformerアーキテクチャとSNNの原理を組み合わせた、フラッグシップのハイブリッド言語モデル。
- **ハイブリッド検索RAG**: Milvus（ベクトル検索）とElasticsearch（キーワード検索）を使用し、結果をReciprocal Rank Fusion (RRF)で統合するRetrieval-Augmented Generationシステム。
- **フェデレーテッド学習**: `Flower`フレームワークを用いた、プライバシーを保護する分散学習のサポート。知識共有に「スパイク蒸留」を用いる特殊な`DistributedBrainClient`を含む。
- **RESTful API & SDK**: `FastAPI`サーバーとそれに対応する`EvoSpikeNetAPIClient`が、フレームワークの機能へプログラムでアクセスするための主要なインターフェースを提供。
